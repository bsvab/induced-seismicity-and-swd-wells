{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyproj\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial filtering and cleaning of the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of substrings to be removed\n",
    "remove_substrings = [\"PROPERTY: Pressure\", \"UNITS:    psi\", \"<\", \">\", \"** \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file\n",
    "with open(\"ndb_deep_oct2023_Pressure_allLayers_starting20170101.txt\", \"r\") as file:\n",
    "    # Read the lines and filter out lines containing specified substrings\n",
    "    lines = []\n",
    "    for line in file:\n",
    "        if \"** TIME\" in line:\n",
    "            line = line.replace(\"** \", \"\", 1)  # Remove only the first occurrence of \"** \"\n",
    "            line = line.replace(\":\", \"\", 1)  # Remove only the first occurrence of \"** \"\n",
    "        elif \"<\" in line or \">\" in line:  # Check for \"<\" or \">\" in the line\n",
    "            line = line.replace(\"<\", \"\").replace(\">\", \"\")  # Remove \"<\" and \">\"\n",
    "        elif any(substring in line for substring in remove_substrings):\n",
    "            continue  # Skip lines containing other specified substrings\n",
    "        lines.append(line.strip())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export filtered lines to a new text file\n",
    "with open(\"filtered_output.txt\", \"w\") as output_file:\n",
    "    for line in lines:\n",
    "        output_file.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the new text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the file\n",
    "with open('filtered_output.txt', 'r') as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the lines\n",
    "for i, line in enumerate(lines):\n",
    "    if \"Layer    1\" in line:\n",
    "        lines[i] = line.replace(\"Layer    1\", \"Layer_1\")\n",
    "    elif \"Layer    2\" in line:\n",
    "        lines[i] = line.replace(\"Layer    2\", \"Layer_2\")\n",
    "    elif \"Layer    3\" in line:\n",
    "        lines[i] = line.replace(\"Layer    3\", \"Layer_3\")\n",
    "    elif \"Layer    4\" in line:\n",
    "        lines[i] = line.replace(\"Layer    4\", \"Layer_4\")\n",
    "    elif \"Layer    5\" in line:\n",
    "        lines[i] = line.replace(\"Layer    5\", \"Layer_5\")\n",
    "    elif \"Layer    6\" in line:\n",
    "        lines[i] = line.replace(\"Layer    6\", \"Layer_6\")\n",
    "    elif \"Layer    7\" in line:\n",
    "        lines[i] = line.replace(\"Layer    7\", \"Layer_7\")\n",
    "    elif \"Layer    8\" in line:\n",
    "        lines[i] = line.replace(\"Layer    8\", \"Layer_8\")\n",
    "    elif \"Layer    9\" in line:\n",
    "        lines[i] = line.replace(\"Layer    9\", \"Layer_9\")\n",
    "    elif \"Layer   10\" in line:\n",
    "        lines[i] = line.replace(\"Layer   10\", \"Layer_10\")\n",
    "    elif \"Layer   11\" in line:\n",
    "        lines[i] = line.replace(\"Layer   11\", \"Layer_11\")\n",
    "    elif \"Layer   12\" in line:\n",
    "        lines[i] = line.replace(\"Layer   12\", \"Layer_12\")\n",
    "    elif \"Layer   13\" in line:\n",
    "        lines[i] = line.replace(\"Layer   13\", \"Layer_13\")\n",
    "    elif \"Layer   14\" in line:\n",
    "        lines[i] = line.replace(\"Layer   14\", \"Layer_14\")\n",
    "    elif \"Layer   15\" in line:\n",
    "        lines[i] = line.replace(\"Layer   15\", \"Layer_15\")\n",
    "    elif \"Layer   16\" in line:\n",
    "        lines[i] = line.replace(\"Layer   16\", \"Layer_16\")\n",
    "    elif \"Layer   17\" in line:\n",
    "        lines[i] = line.replace(\"Layer   17\", \"Layer_17\")\n",
    "    elif \"Layer   18\" in line:\n",
    "        lines[i] = line.replace(\"Layer   18\", \"Layer_18\")\n",
    "    elif \"Layer   19\" in line:\n",
    "        lines[i] = line.replace(\"Layer   19\", \"Layer_19\")\n",
    "    elif \"Layer   20\" in line:\n",
    "        lines[i] = line.replace(\"Layer   20\", \"Layer_20\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacement completed!\n"
     ]
    }
   ],
   "source": [
    "# Write the modified lines to a new file\n",
    "with open('output_file.txt', 'w') as file:\n",
    "    file.writelines(lines)\n",
    "\n",
    "print(\"Replacement completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the text file into a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the text file\n",
    "with open('output_file.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Initialize variables to store the CSV data\n",
    "csv_data = []\n",
    "current_time = None\n",
    "\n",
    "# Process each line of the input data\n",
    "for line in lines:\n",
    "    line = line.strip()  # Remove leading/trailing whitespace\n",
    "    if line.startswith(\"TIME\"):\n",
    "        current_time = line.split()[1]  # Extract the TIME value\n",
    "    elif line:  # Non-empty line\n",
    "        parts = line.split()  # Split the line by whitespace\n",
    "        print(parts)\n",
    "        if len(parts) >= 3:  # Check if line has enough elements\n",
    "            x, y, layer_value = parts[0], parts[1], parts[2]\n",
    "            layer_number = parts[-1]  # Extract layer number from the header\n",
    "            csv_data.append([current_time, x, y, layer_value, layer_number])\n",
    "\n",
    "# Write the CSV data to a new file\n",
    "with open('output.csv', 'w') as csv_file:\n",
    "    # Write headers\n",
    "    csv_file.write('Time,X,Y,Layer,Layer Number\\n')\n",
    "    # Write data\n",
    "    for entry in csv_data:\n",
    "        csv_file.write(','.join(entry) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the data in the CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame using the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the directory of the current script\n",
    "current_directory = os.getcwd()\n",
    "# Name of your CSV file\n",
    "filename = 'output.csv'\n",
    "\n",
    "# Construct the file path using os.path.join\n",
    "file_path = os.path.join(current_directory, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df = df.rename(columns={\n",
    "    'Time' : 'Time',\n",
    "    'X' : 'X',\n",
    "    'Y' : 'Y',\n",
    "    'Layer' : 'Pressure',\n",
    "    'Layer Number' : 'Layer'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41670</td>\n",
       "      <td>X</td>\n",
       "      <td>Y</td>\n",
       "      <td>Layer_1</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41670</td>\n",
       "      <td>2106604.41</td>\n",
       "      <td>3434119.83</td>\n",
       "      <td>7952.25</td>\n",
       "      <td>7952.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41670</td>\n",
       "      <td>2111884.40</td>\n",
       "      <td>3434119.83</td>\n",
       "      <td>7970.05</td>\n",
       "      <td>7970.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41670</td>\n",
       "      <td>2037964.57</td>\n",
       "      <td>3439399.82</td>\n",
       "      <td>7658.27</td>\n",
       "      <td>7658.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41670</td>\n",
       "      <td>2043244.56</td>\n",
       "      <td>3439399.82</td>\n",
       "      <td>7754</td>\n",
       "      <td>7754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time           X           Y Pressure    Layer\n",
       "0  41670           X           Y  Layer_1  Layer_1\n",
       "1  41670  2106604.41  3434119.83  7952.25  7952.25\n",
       "2  41670  2111884.40  3434119.83  7970.05  7970.05\n",
       "3  41670  2037964.57  3439399.82  7658.27  7658.27\n",
       "4  41670  2043244.56  3439399.82     7754     7754"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the values in the Layer column with the actual Layer Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate the dataframe\n",
    "df_dupe = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize number variable\n",
    "number = None\n",
    "\n",
    "# Iterate over each row\n",
    "for index, row in df_dupe.iterrows():\n",
    "    if row['Pressure'].startswith('Layer_'):\n",
    "        number = row['Pressure']\n",
    "\n",
    "    df_dupe.at[index, 'Layer'] = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41670</td>\n",
       "      <td>X</td>\n",
       "      <td>Y</td>\n",
       "      <td>Layer_1</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41670</td>\n",
       "      <td>2106604.41</td>\n",
       "      <td>3434119.83</td>\n",
       "      <td>7952.25</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41670</td>\n",
       "      <td>2111884.40</td>\n",
       "      <td>3434119.83</td>\n",
       "      <td>7970.05</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41670</td>\n",
       "      <td>2037964.57</td>\n",
       "      <td>3439399.82</td>\n",
       "      <td>7658.27</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41670</td>\n",
       "      <td>2043244.56</td>\n",
       "      <td>3439399.82</td>\n",
       "      <td>7754</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time           X           Y Pressure    Layer\n",
       "0  41670           X           Y  Layer_1  Layer_1\n",
       "1  41670  2106604.41  3434119.83  7952.25  Layer_1\n",
       "2  41670  2111884.40  3434119.83  7970.05  Layer_1\n",
       "3  41670  2037964.57  3439399.82  7658.27  Layer_1\n",
       "4  41670  2043244.56  3439399.82     7754  Layer_1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "df_dupe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to remove rows where 'X' column is equal to 'X'\n",
    "df_dupe = df_dupe[df_dupe['X'] != 'X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41670</td>\n",
       "      <td>2106604.41</td>\n",
       "      <td>3434119.83</td>\n",
       "      <td>7952.25</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41670</td>\n",
       "      <td>2111884.40</td>\n",
       "      <td>3434119.83</td>\n",
       "      <td>7970.05</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41670</td>\n",
       "      <td>2037964.57</td>\n",
       "      <td>3439399.82</td>\n",
       "      <td>7658.27</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41670</td>\n",
       "      <td>2043244.56</td>\n",
       "      <td>3439399.82</td>\n",
       "      <td>7754</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41670</td>\n",
       "      <td>2048524.55</td>\n",
       "      <td>3439399.82</td>\n",
       "      <td>7828.24</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time           X           Y Pressure    Layer\n",
       "1  41670  2106604.41  3434119.83  7952.25  Layer_1\n",
       "2  41670  2111884.40  3434119.83  7970.05  Layer_1\n",
       "3  41670  2037964.57  3439399.82  7658.27  Layer_1\n",
       "4  41670  2043244.56  3439399.82     7754  Layer_1\n",
       "5  41670  2048524.55  3439399.82  7828.24  Layer_1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the DataFrame\n",
    "df_dupe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covert the Time column values to DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate the df_dupe DataFrame\n",
    "df_time = df_dupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\2130526349.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_time['Time'] = pd.to_datetime('1902-12-01') + pd.to_timedelta(df_time['Time'], unit='D')\n"
     ]
    }
   ],
   "source": [
    "# Convert time to dates\n",
    "df_time['Time'] = pd.to_datetime('1902-12-01') + pd.to_timedelta(df_time['Time'], unit='D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Layer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2106604.41</td>\n",
       "      <td>3434119.83</td>\n",
       "      <td>7952.25</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2111884.40</td>\n",
       "      <td>3434119.83</td>\n",
       "      <td>7970.05</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2037964.57</td>\n",
       "      <td>3439399.82</td>\n",
       "      <td>7658.27</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2043244.56</td>\n",
       "      <td>3439399.82</td>\n",
       "      <td>7754</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2048524.55</td>\n",
       "      <td>3439399.82</td>\n",
       "      <td>7828.24</td>\n",
       "      <td>Layer_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time           X           Y Pressure    Layer\n",
       "1 2017-01-01  2106604.41  3434119.83  7952.25  Layer_1\n",
       "2 2017-01-01  2111884.40  3434119.83  7970.05  Layer_1\n",
       "3 2017-01-01  2037964.57  3439399.82  7658.27  Layer_1\n",
       "4 2017-01-01  2043244.56  3439399.82     7754  Layer_1\n",
       "5 2017-01-01  2048524.55  3439399.82  7828.24  Layer_1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the DataFrame with the updated values\n",
    "df_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export df_time to a CSV file\n",
    "df_time.to_csv('Updated_Pressure_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the Coordinate system from NAD 1927 to WGS 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Updated_Pressure_Data_with_LatLon.csv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the custom Lambert Conformal Conic projection\n",
    "proj_string = \"\"\"\n",
    "    +proj=lcc +datum=NAD83 +ellps=GRS80 +lon_0=-100 +lat_1=27.4166666666667\n",
    "    +lat_2=34.9166666666667 +lat_0=31.1666666666667 +x_0=999999.9998984\n",
    "    +y_0=999999.9998984 +unit=us-ft +no_defs\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the Transformer object\n",
    "transformer = pyproj.Transformer.from_proj(\n",
    "    pyproj.Proj(proj_string),  # Source coordinate system\n",
    "    pyproj.Proj(proj='latlong', datum='WGS84'),  # Destination coordinate system\n",
    "    always_xy=True  \n",
    ")\n",
    "\n",
    "# Load the CSV file in chunks\n",
    "csv_file_path = 'Updated_Pressure_Data.csv' \n",
    "\n",
    "# Set up a CSV writer to write the output to a new file\n",
    "output_csv_path = 'Updated_Pressure_Data_with_LatLon.csv'\n",
    "chunksize = 10000  # Process 10,000 rows at a time\n",
    "\n",
    "# Write the header first\n",
    "first_chunk = True\n",
    "\n",
    "for chunk in pd.read_csv(csv_file_path, chunksize=chunksize):\n",
    "    # Convert from US feet to meters\n",
    "    chunk['X_meters'] = chunk['X'] * 0.3048\n",
    "    chunk['Y_meters'] = chunk['Y'] * 0.3048\n",
    "\n",
    "    # Transform to lat, lon\n",
    "    chunk['Longitude'], chunk['Latitude'] = transformer.transform(chunk['X_meters'].values, chunk['Y_meters'].values)  \n",
    "\n",
    "    # Drop the intermediate columns\n",
    "    chunk.drop(['X_meters', 'Y_meters', 'X', 'Y'], axis=1, inplace=True)\n",
    "\n",
    "    # Write the chunk to a CSV\n",
    "    mode = 'w' if first_chunk else 'a'\n",
    "    header = first_chunk  # Write header only in the first chunk\n",
    "    chunk.to_csv(output_csv_path, mode=mode, index=False, header=header)\n",
    "    first_chunk = False\n",
    "\n",
    "# Return the path to the new CSV file\n",
    "output_csv_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Pressure Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Layer</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Delta_Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2580.60</td>\n",
       "      <td>Layer_13</td>\n",
       "      <td>-105.142041</td>\n",
       "      <td>32.563859</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>2580.65</td>\n",
       "      <td>Layer_13</td>\n",
       "      <td>-105.142041</td>\n",
       "      <td>32.563859</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2580.68</td>\n",
       "      <td>Layer_13</td>\n",
       "      <td>-105.142041</td>\n",
       "      <td>32.563859</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2580.72</td>\n",
       "      <td>Layer_13</td>\n",
       "      <td>-105.142041</td>\n",
       "      <td>32.563859</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>2580.76</td>\n",
       "      <td>Layer_13</td>\n",
       "      <td>-105.142041</td>\n",
       "      <td>32.563859</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time  Pressure     Layer   Longitude   Latitude  Delta_Pressure\n",
       "0 2017-01-01   2580.60  Layer_13 -105.142041  32.563859            0.00\n",
       "1 2017-02-01   2580.65  Layer_13 -105.142041  32.563859            0.05\n",
       "2 2017-03-01   2580.68  Layer_13 -105.142041  32.563859            0.08\n",
       "3 2017-04-01   2580.72  Layer_13 -105.142041  32.563859            0.12\n",
       "4 2017-05-01   2580.76  Layer_13 -105.142041  32.563859            0.16"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file again\n",
    "df = pd.read_csv('Updated_Pressure_Data_with_LatLon.csv')\n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "layer_13_df = df[df['Layer'] == 'Layer_13']\n",
    "\n",
    "# Group by Longitude and Latitude for unique locations within Layer_13\n",
    "grouped = layer_13_df.groupby(['Longitude', 'Latitude'])\n",
    "\n",
    "# Initialize an empty DataFrame for results\n",
    "delta_pressure_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each group\n",
    "for (longitude, latitude), group in grouped:\n",
    "    # Filter to get the reference pressure on 2017-01-01 for each location\n",
    "    reference_pressure_row = group[group['Time'] == pd.Timestamp('2017-01-01')]\n",
    "    if not reference_pressure_row.empty:\n",
    "        reference_pressure = reference_pressure_row.iloc[0]['Pressure']\n",
    "        # Calculate delta pressure for each row in the group by subtracting the reference pressure\n",
    "        group['Delta_Pressure'] = group['Pressure'] - reference_pressure\n",
    "        # Append the processed group to the results DataFrame\n",
    "        delta_pressure_df = pd.concat([delta_pressure_df, group])\n",
    "\n",
    "# Resetting index of the final DataFrame\n",
    "delta_pressure_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save the results DataFrame for this layer to a CSV file\n",
    "output_path = f'delta_pressure_layer13.csv'\n",
    "delta_pressure_df.to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "# Checking the first few rows of the final DataFrame\n",
    "delta_pressure_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
      "C:\\Users\\ajuar\\AppData\\Local\\Temp\\ipykernel_19804\\1546589455.py:30: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        Time  Pressure    Layer   Longitude   Latitude  Delta\n",
       " 0 2017-01-01   1595.32  Layer_1 -105.142041  32.563859   0.00\n",
       " 1 2017-02-01   1595.37  Layer_1 -105.142041  32.563859   0.05\n",
       " 2 2017-03-01   1595.42  Layer_1 -105.142041  32.563859   0.10\n",
       " 3 2017-04-01   1595.47  Layer_1 -105.142041  32.563859   0.15\n",
       " 4 2017-05-01   1595.52  Layer_1 -105.142041  32.563859   0.20,\n",
       " 'delta_pressure_all_layers.csv')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate delta pressure\n",
    "def calculate_delta_pressure(group):\n",
    "    # Sort group by time\n",
    "    group = group.sort_values('Time')\n",
    "    # Get the reference pressure from the first date (assumed to be the earliest in the group)\n",
    "    reference_pressure = group.iloc[0]['Pressure']\n",
    "    # Calculate delta pressure\n",
    "    group['Delta'] = group['Pressure'] - reference_pressure\n",
    "    return group\n",
    "\n",
    "# Read CSV\n",
    "df_path = 'Updated_Pressure_Data_with_LatLon.csv'\n",
    "df = pd.read_csv(df_path)\n",
    "\n",
    "# Convert 'Time' to datetime\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "# Get unique layers\n",
    "layers = df['Layer'].unique()\n",
    "\n",
    "# Initialize a DataFrame to store all the delta pressures\n",
    "all_layers_delta_df = pd.DataFrame()\n",
    "\n",
    "# Calculate delta pressure for each layer and append to the all_layers_delta_df DataFrame\n",
    "for layer in layers:\n",
    "    layer_df = df[df['Layer'] == layer]\n",
    "    # Group by 'Longitude' and 'Latitude' to handle each location separately\n",
    "    grouped = layer_df.groupby(['Longitude', 'Latitude'])\n",
    "    # Apply the calculate_delta_pressure function to each group\n",
    "    delta_df = grouped.apply(calculate_delta_pressure).reset_index(drop=True)\n",
    "    # Append to the all_layers_delta_df DataFrame\n",
    "    all_layers_delta_df = pd.concat([all_layers_delta_df, delta_df], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file without headers for subsequent rows\n",
    "output_file = 'delta_pressure_all_layers.csv'\n",
    "all_layers_delta_df.to_csv(output_file, index=False)\n",
    "\n",
    "all_layers_delta_df.head(), output_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
